{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rib0VDKT8FJg",
        "outputId": "2a5bab27-4d40-4e78-de88-42ffb1beeb43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.1/108.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.4/635.4 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install \\\n",
        "  notebook \\\n",
        "  aiohttp \\\n",
        "  faiss-cpu \\\n",
        "  \"torch>=2.2,<3.0\" \\\n",
        "  sentence-transformers \\\n",
        "  tree_sitter_python \\\n",
        "  tree_sitter \\\n",
        "  google.genai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uF5K2l6c7eBy"
      },
      "outputs": [],
      "source": [
        "import httpx\n",
        "import asyncio\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "async def fetch_github_repo_content(url: str) -> dict:\n",
        "    headers = {\n",
        "        \"Accept\": \"application/vnd.github.object\",\n",
        "        \"X-GitHub-Api-Version\": \"2022-11-28\"\n",
        "    }\n",
        "\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        response = await client.get(url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    return {}\n",
        "\n",
        "async def fetch_file_content_from_download_url(download_url: str, client: httpx.AsyncClient, semaphore: asyncio.Semaphore) -> str:\n",
        "    async with semaphore:\n",
        "        response = await client.get(download_url)\n",
        "        response.raise_for_status()\n",
        "        return response.text\n",
        "    return \"\"\n",
        "\n",
        "async def fetch_list_of_file_name_content_tuples(github_repo_content: dict, max_concurrent: int = 3):\n",
        "    python_files = [item for item in github_repo_content['entries'] if item['name'].endswith('.py')]\n",
        "    semaphore = asyncio.Semaphore(max_concurrent)\n",
        "\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        content_tasks = []\n",
        "        for pf in python_files:\n",
        "            content_task = fetch_file_content_from_download_url(\n",
        "                pf['download_url'],\n",
        "                client,\n",
        "                semaphore\n",
        "            )\n",
        "            content_tasks.append(content_task)\n",
        "\n",
        "        contents = await asyncio.gather(*content_tasks)\n",
        "\n",
        "    name_content_tuples = list(zip([pf['name'] for pf in python_files], contents))\n",
        "    return name_content_tuples\n",
        "\n",
        "\n",
        "def write_python_files(relative_path: str, name_content_tuples: list) -> None:\n",
        "    output_dir = Path.cwd() / relative_path\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    for name, content in name_content_tuples:\n",
        "        file_path = output_dir / name\n",
        "        file_path.write_text(content, encoding='utf-8')\n",
        "\n",
        "\n",
        "async def fetch_urls_and_save_in_dirs():\n",
        "    urls = [\n",
        "        \"https://api.github.com/repos/neetcode-gh/leetcode/contents/python?ref=main\",\n",
        "        \"https://api.github.com/repos/TheAlgorithms/Python/contents/sorts?ref=master\"\n",
        "    ]\n",
        "\n",
        "    dir_names = ['neetcode', 'sorts']\n",
        "    for i in range(len(dir_names)):\n",
        "        url = urls[i]\n",
        "        dir_name = dir_names[i]\n",
        "\n",
        "        repo = await fetch_github_repo_content(url)\n",
        "        names_contents = await fetch_list_of_file_name_content_tuples(repo)\n",
        "        write_python_files(dir_name, names_contents)\n",
        "\n",
        "await fetch_urls_and_save_in_dirs()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NMU4adEt7hTa"
      },
      "outputs": [],
      "source": [
        "import tree_sitter_python as tspython\n",
        "from tree_sitter import Language, Parser\n",
        "from pathlib import Path\n",
        "PY_LANGUAGE = Language(tspython.language())\n",
        "parser = Parser(PY_LANGUAGE)\n",
        "\n",
        "\n",
        "def chunk_python_code_in_functions_and_classes(code:str):\n",
        "    tree = parser.parse(bytes(code, \"utf8\"))\n",
        "    root_node = tree.root_node\n",
        "    function_node = root_node.children\n",
        "    functions_and_classes = [f for f in function_node if f.type in ['function_definition', 'class_definition']]\n",
        "    return [fc.text for fc in functions_and_classes]\n",
        "\n",
        "\n",
        "def get_chunks_of_fuctions_and_classes_from_dir(dir_path):\n",
        "    base = Path(dir_path)\n",
        "    result = []\n",
        "    for file in base.rglob(\"*\"):\n",
        "        if file.is_file() and file.suffix == '.py':\n",
        "            code = file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "            chunks = chunk_python_code_in_functions_and_classes(code)\n",
        "            result.extend(chunks)\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "LDTWBRYz7jrz"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.colab import userdata\n",
        "from google.genai import types\n",
        "google_key = userdata.get('GEMINI_API_KEY')\n",
        "client = genai.Client(api_key=google_key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qZUDc2Gm7k4S"
      },
      "outputs": [],
      "source": [
        "def generate_embeddings(chunks:list[str]):\n",
        "  result = client.models.embed_content(\n",
        "          model=\"gemini-embedding-001\",\n",
        "          contents=chunks,\n",
        "          config=types.EmbedContentConfig(task_type=\"RETRIEVAL_DOCUMENT\")\n",
        "          )\n",
        "  embeddings = np.array([embedding.values for embedding in result.embeddings])\n",
        "  embeddings = embeddings.astype('float32')\n",
        "\n",
        "  return embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "FTDxqMAI7mW6"
      },
      "outputs": [],
      "source": [
        "chunks = get_chunks_of_fuctions_and_classes_from_dir('sorts')\n",
        "embeddings = generate_embeddings(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "tJqyRTiN7nia"
      },
      "outputs": [],
      "source": [
        "import numpy as np, faiss\n",
        "dim = embeddings.shape[1]\n",
        "faiss.normalize_L2(embeddings)\n",
        "metric = faiss.METRIC_INNER_PRODUCT\n",
        "M=32\n",
        "base = faiss.IndexHNSWFlat(dim, M, metric)\n",
        "base.hnsw.efConstruction = 200\n",
        "base.hnsw.efSearch = 64\n",
        "index = faiss.IndexIDMap2(base)\n",
        "ids = [i for i in range(embeddings.shape[0])]\n",
        "ids = np.array(ids)\n",
        "index.add_with_ids(embeddings, ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWMzRaHZ7o0J",
        "outputId": "0f6ef1c8-ff91-467c-86dc-1f87b7a2779a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.9952494  0.81578714 0.808552   0.8019581  0.792458  ]] [[77 67  0  2 33]]\n"
          ]
        }
      ],
      "source": [
        "code = \"\"\"\n",
        "\n",
        "def bucket_sort(my_list: list, bucket_count: int = 10) -> list:\n",
        "    \"\"\n",
        "    >>> data = [-1, 2, -5, 0]\n",
        "    >>> bucket_sort(data) == sorted(data)\n",
        "    True\n",
        "    >>> data = [9, 8, 7, 6, -12]\n",
        "    >>> bucket_sort(data) == sorted(data)\n",
        "    True\n",
        "    >>> data = [.4, 1.2, .1, .2, -.9]\n",
        "    >>> bucket_sort(data) == sorted(data)\n",
        "    True\n",
        "    >>> bucket_sort([]) == sorted([])\n",
        "    True\n",
        "   2, 2, 1, 1, 3]\n",
        "    >>> bucket_sort(data) == sorted(data)\n",
        "    True\n",
        "    >>> data = [5, 5, 5, 5, 5]\n",
        "\"\"\"\n",
        "search_chunks = [code]\n",
        "search_embed = generate_embeddings(search_chunks)\n",
        "faiss.normalize_L2(search_embed)\n",
        "D, I = index.search(search_embed, k=5)\n",
        "\n",
        "print(D,I)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg6TGAyc9Hy2",
        "outputId": "a2a3bb21-21b1-4d9e-b342-545fc8cad8d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'def bucket_sort(my_list: list, bucket_count: int = 10) -> list:\\n    \"\"\"\\n    >>> data = [-1, 2, -5, 0]\\n    >>> bucket_sort(data) == sorted(data)\\n    True\\n    >>> data = [9, 8, 7, 6, -12]\\n    >>> bucket_sort(data) == sorted(data)\\n    True\\n    >>> data = [.4, 1.2, .1, .2, -.9]\\n    >>> bucket_sort(data) == sorted(data)\\n    True\\n    >>> bucket_sort([]) == sorted([])\\n    True\\n    >>> data = [-1e10, 1e10]\\n    >>> bucket_sort(data) == sorted(data)\\n    True\\n    >>> import random\\n    >>> collection = random.sample(range(-50, 50), 50)\\n    >>> bucket_sort(collection) == sorted(collection)\\n    True\\n    >>> data = [1, 2, 2, 1, 1, 3]\\n    >>> bucket_sort(data) == sorted(data)\\n    True\\n    >>> data = [5, 5, 5, 5, 5]\\n    >>> bucket_sort(data) == sorted(data)\\n    True\\n    >>> data = [1000, -1000, 500, -500, 0]\\n    >>> bucket_sort(data) == sorted(data)\\n    True\\n    >>> data = [5.5, 2.2, -1.1, 3.3, 0.0]\\n    >>> bucket_sort(data) == sorted(data)\\n    True\\n    >>> bucket_sort([1]) == [1]\\n    True\\n    >>> data = [-1.1, -1.5, -3.4, 2.5, 3.6, -3.3]\\n    >>> bucket_sort(data) == sorted(data)\\n    True\\n    >>> data = [9, 2, 7, 1, 5]\\n    >>> bucket_sort(data) == sorted(data)\\n    True\\n    \"\"\"\\n\\n    if len(my_list) == 0 or bucket_count <= 0:\\n        return []\\n\\n    min_value, max_value = min(my_list), max(my_list)\\n    if min_value == max_value:\\n        return my_list\\n\\n    bucket_size = (max_value - min_value) / bucket_count\\n    buckets: list[list] = [[] for _ in range(bucket_count)]\\n\\n    for val in my_list:\\n        index = min(int((val - min_value) / bucket_size), bucket_count - 1)\\n        buckets[index].append(val)\\n\\n    return [val for bucket in buckets for val in sorted(bucket)]'\n"
          ]
        }
      ],
      "source": [
        "print(chunks[77])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE2rHcx8_ej0",
        "outputId": "59af7069-6676-4710-da3e-41ebbd070f02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FlatIP: [[0.4405725 0.4405725 0.4405725 0.4405725 0.4405725]] [[14 13 12 11 10]]\n"
          ]
        }
      ],
      "source": [
        "ip_index = faiss.IndexFlatIP(embeddings.shape[1])\n",
        "ip_index.add(embeddings.copy())  # copy to avoid any accidental mutation\n",
        "D0, I0 = ip_index.search(search_embed, k=5)\n",
        "print(\"FlatIP:\", D0, I0)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "code-plagiarism-detector",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
